# KVCache Chatbot

A multi-turn conversation chatbot with document upload support, featuring a clean separation between frontend (Gradio) and backend (FastAPI).

## Features

- ğŸ’¬ **Multi-turn Conversations**: Maintains conversation history for context-aware responses
- ğŸ“„ **Document Upload**: Upload documents and ask questions about their content
- âš¡ **Streaming Responses**: Real-time streaming for better user experience
- ğŸ”Œ **Frontend-Backend Separation**: Clean REST API architecture
- ğŸš€ **Extensible Design**: Easy to add new document formats and LLM providers

## Architecture

```
kvcache_chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ main.py       # Main application
â”‚   â”‚   â”œâ”€â”€ config.py     # Configuration
â”‚   â”‚   â”œâ”€â”€ models.py     # Data models
â”‚   â”‚   â”œâ”€â”€ routers/      # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py   # Chat endpoints
â”‚   â”‚   â”‚   â””â”€â”€ upload.py # File upload endpoints
â”‚   â”‚   â””â”€â”€ services/     # Business logic
â”‚   â”‚       â”œâ”€â”€ session_service.py   # Session management
â”‚   â”‚       â”œâ”€â”€ document_service.py  # Document processing
â”‚   â”‚       â””â”€â”€ llm_service.py       # LLM integration
â”‚   â””â”€â”€ web/              # Gradio frontend
â”‚       â””â”€â”€ app.py        # Gradio interface
â””â”€â”€ README.md
```

## Prerequisites

- Python 3.10+
- Virtual environment activated: `source .venv/bin/activate`

## Installation

### 1. Activate Virtual Environment

```bash
source .venv/bin/activate
```

### 2. Install Backend Dependencies

```bash
cd src/api
pip install -r requirements.txt
```

### 3. Install Frontend Dependencies

```bash
cd ../web
pip install -r requirements.txt
```

## Running the Application

### Quick Start (Recommended)

**ä¸€éµå•Ÿå‹•å‰å¾Œç«¯ï¼š**

```bash
source .venv/bin/activate
./start.sh
```

é€™å€‹è…³æœ¬æœƒï¼š
- âœ… è‡ªå‹•æª¢æŸ¥ä¸¦å®‰è£ä¾è³´
- âœ… å¾Œå°å•Ÿå‹•å¾Œç«¯ (port 8000)
- âœ… å‰å°å•Ÿå‹•å‰ç«¯ (port 7860)
- âœ… æŒ‰ `Ctrl+C` æœƒåŒæ™‚åœæ­¢å…©å€‹æœå‹™

**åœæ­¢æœå‹™ï¼š**

```bash
./stop.sh
```

æˆ–ç›´æ¥åœ¨é‹è¡Œçš„çµ‚ç«¯æŒ‰ `Ctrl+C`

### Manual Start (Alternative)

å¦‚æœä½ æƒ³åˆ†åˆ¥å•Ÿå‹•å‰å¾Œç«¯ï¼š

**Terminal 1 - Backend:**
```bash
source .venv/bin/activate
./start_backend.sh
```

**Terminal 2 - Frontend:**
```bash
source .venv/bin/activate
./start_frontend.sh
```

### Access Points

- **å‰ç«¯ç•Œé¢**: http://localhost:7860
- **å¾Œç«¯ API**: http://localhost:8000
- **API æ–‡æª”**: http://localhost:8000/docs
- **å¾Œç«¯æ—¥èªŒ**: `logs/backend.log` (çµ±ä¸€å•Ÿå‹•æ™‚)

## Usage

1. **Open the Gradio Interface**: Navigate to http://localhost:7860
2. **Upload a Document** (optional):
   - Click "Upload Document" in the right panel
   - Select a `.txt` file
   - Click "Upload"
3. **Start Chatting**:
   - Type your message in the text box
   - Enable "Use uploaded document context" if you want answers based on the document
   - Click "Send" or press Enter
4. **Multi-turn Conversation**: The chatbot remembers previous messages in the conversation
5. **Clear Chat**: Click "Clear Chat" to start a new session

## API Endpoints

### Chat Endpoints

- `POST /api/v1/chat/message` - Send message (non-streaming)
- `POST /api/v1/chat/stream` - Send message (streaming with SSE)
- `GET /api/v1/chat/session/{session_id}` - Get session info
- `GET /api/v1/chat/history/{session_id}` - Get chat history
- `DELETE /api/v1/chat/session/{session_id}` - Delete session

### Upload Endpoints

- `POST /api/v1/upload` - Upload document
- `DELETE /api/v1/upload/{session_id}` - Delete uploaded document

## Configuration

### LLM API é…ç½®ï¼ˆå¯é¸ï¼‰

åœ¨ `src/api/` ç›®éŒ„ä¸‹å‰µå»º `.env` æ–‡ä»¶ï¼š

```env
# LLM Settings - OpenAI Compatible API
LLM_MODEL=gpt-3.5-turbo
LLM_API_KEY=your-openai-api-key-here
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
```

**æ³¨æ„ï¼š** å¦‚æœä¸é…ç½® API keyï¼Œç³»çµ±æœƒä½¿ç”¨ mock éŸ¿æ‡‰é€²è¡Œæ¸¬è©¦ã€‚

è©³ç´°é…ç½®èªªæ˜è«‹åƒè€ƒï¼š[LLM_SETUP.md](LLM_SETUP.md)

## Extending the System

### Adding New Document Formats

1. Create a processor in `src/api/services/document_service.py`:

```python
class PdfProcessor:
    async def process(self, file_path: Path) -> str:
        # PDF processing logic
        pass

# Register the processor
document_service.register_processor('.pdf', PdfProcessor())
```

2. Update `ALLOWED_EXTENSIONS` in `config.py`
3. Update file types in `src/web/app.py` (line with `file_types=[".txt"]`)

### Integrating Real LLM (OpenAI Compatible API)

ç³»çµ±å·²å…§å»º OpenAI compatible API æ”¯æŒï¼

**å¿«é€Ÿè¨­å®šï¼š**

1. åœ¨ `src/api/` å‰µå»º `.env` æ–‡ä»¶
2. æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š
   ```env
   LLM_MODEL=gpt-3.5-turbo
   LLM_API_KEY=your-openai-api-key-here
   ```
3. é‡å•Ÿå¾Œç«¯å³å¯

**ç²å– API Keyï¼š**
- OpenAI: https://platform.openai.com/api-keys
- è©³ç´°èªªæ˜ï¼šæŸ¥çœ‹ [LLM_SETUP.md](LLM_SETUP.md)

**ä¸é…ç½® API keyï¼Ÿ** ç³»çµ±æœƒä½¿ç”¨ mock éŸ¿æ‡‰ï¼Œé©åˆæ¸¬è©¦ã€‚

### Adding Database Storage

Currently uses in-memory session storage. To add database:

1. Install database driver: `pip install sqlalchemy asyncpg`
2. Create models in `src/api/database.py`
3. Update `SessionManager` in `session_service.py` to use database

## Technology Stack

**Backend:**
- FastAPI - Modern Python web framework
- Pydantic - Data validation
- Uvicorn - ASGI server

**Frontend:**
- Gradio - ML/AI web interface framework
- httpx - HTTP client

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

# chatbot
