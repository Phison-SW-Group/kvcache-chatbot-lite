{
  "name": "kvcache-chatbot",
  "version": "1.0.0",
  "description": "KVCache Chatbot - Cross-platform task runner",
  "main": "index.js",
  "scripts": {
    "help": "npm run",
    "install-deps": "uv sync && mkdir -p logs src/api/uploads",
    "backend": "cd src/api && python main.py --port 3023",
    "frontend": "cd src/web && python app.py --backend-port 3023",
    "start": "npm run backend & npm run frontend",
    "all": "npm start",
    "stop": "lsof -ti:3023 | xargs kill -9 2>/dev/null; lsof -ti:7860 | xargs kill -9 2>/dev/null",
    "clean": "rm -f logs/*.log && rm -rf src/api/uploads/*",
    "logs": "tail -f logs/backend.log",
    "test": "curl -s http://0.0.0.0:3023/health && curl -s http://0.0.0.0:7860 > /dev/null",
    "dev": "cd src/api && python main.py & sleep 5 && npm run frontend",
    "setup": "npm run install-deps && echo '# LLM Configuration' > .env.template && echo 'LLM_MODEL=gpt-3.5-turbo' >> .env.template && echo 'LLM_API_KEY=your_api_key_here' >> .env.template && echo 'LLM_BASE_URL=' >> .env.template && echo 'LLM_TEMPERATURE=0.7' >> .env.template && echo 'LLM_MAX_TOKENS=2000' >> .env.template"
  },
  "keywords": [
    "chatbot",
    "kv-cache",
    "fastapi",
    "gradio",
    "python"
  ],
  "author": "KVCache Team",
  "license": "MIT",
  "engines": {
    "node": ">=14.0.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/your-org/kvcache-chatbot"
  }
}
